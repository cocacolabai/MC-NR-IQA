{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Monte Carlo NR-IQA using Fully Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T15:34:42.701133Z",
     "start_time": "2017-08-21T15:34:40.434150Z"
    },
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU(s): ['/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import smtplib\n",
    "import random\n",
    "from os                           import listdir\n",
    "from os.path                      import isfile, join\n",
    "from PIL                          import Image\n",
    "\n",
    "import numpy      as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from tensorflow.python.client     import device_lib\n",
    "from keras.models                 import Model, Sequential, load_model\n",
    "from keras.layers                 import Input, Dense, Activation, BatchNormalization, Reshape, Dropout, LeakyReLU, PReLU, Lambda\n",
    "from keras.layers                 import Flatten, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, concatenate, add\n",
    "from keras.optimizers             import Adam, RMSprop, SGD\n",
    "from keras.losses                 import mean_squared_error, mean_absolute_error\n",
    "from keras.preprocessing.image    import load_img, img_to_array\n",
    "from keras.utils                  import np_utils\n",
    "from keras.utils.vis_utils        import plot_model\n",
    "from keras.callbacks              import TensorBoard, LearningRateScheduler\n",
    "from keras                        import regularizers\n",
    "\n",
    "from scipy.misc                   import imsave, imresize\n",
    "from scipy.signal                 import convolve2d\n",
    "from scipy.stats                  import spearmanr, pearsonr, kendalltau, iqr\n",
    "#from skimage.measure              import block_reduce\n",
    "\n",
    "import matlab\n",
    "import matlab.engine\n",
    "\n",
    "from __future__                   import print_function\n",
    "from IPython.display              import clear_output\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Using GPU(s):', [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T15:34:43.070881Z",
     "start_time": "2017-08-21T15:34:42.703123Z"
    },
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def loadRawData():\n",
    "    # =================================================================================================\n",
    "    # Dataset hyperparams\n",
    "    \n",
    "    scenes = ['cbox', 'torus', 'veach_bidir', 'veach_door', 'sponza']\n",
    "    algs   = ['path', 'bdpt', 'pssmlt', 'mlt', 'manifold-mlt', 'erpt', 'manifold-erpt']\n",
    "    gtalgs = np.array([ 0,  1,  1,  1,  0], dtype=np.uint8) # 0 -> Path, 1 -> BDPT\n",
    "    gtspps = np.array([16, 19, 19, 19, 16], dtype=np.uint8)\n",
    "    \n",
    "    # =================================================================================================\n",
    "    # Initialize Dataset dict\n",
    "    \n",
    "    # Open an arbitrary image to find the common resolution for all images\n",
    "    img  = Image.open('./MonteCarlo-IMDB/cbox/bdpt - 0000000002.png') \n",
    "    h, w = img.size[1], img.size[0]\n",
    "    \n",
    "    data = {'image'    : np.empty((0, h, w, 3), dtype=np.uint8),   # Pixel values in the range  [0, 256)\n",
    "            'depth'    : np.empty((0, h, w, 1), dtype=np.float32), # Pixel values in the range  [0, 1)\n",
    "            'normal'   : np.empty((0, h, w, 3), dtype=np.float32), # Pixel values in the range  [0, 1)\n",
    "            'position' : np.empty((0, h, w, 3), dtype=np.float32), # Pixel values in the range  [0, 1)\n",
    "            'scene'    : np.empty((0, 1),       dtype=np.uint8),   # Scene indices in the range [0,   5)\n",
    "            'alg'      : np.empty((0, 1),       dtype=np.uint8),   # Alg indices in the range   [0,   7)\n",
    "            'spp'      : np.empty((0, 1),       dtype=np.uint8),   # Samples in the range       [0,  19)\n",
    "            'gt'       : np.empty((0, 1),       dtype=np.uint16)}  # GT index in the range      [0, 547)\n",
    "            \n",
    "    \n",
    "    # =================================================================================================\n",
    "    # For each scene load and append all images along with basic meta data\n",
    "    \n",
    "    for sidx, scene in enumerate(scenes):\n",
    "        path  = './MonteCarlo-IMDB/%s' % (scene)\n",
    "        files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "        \n",
    "        # Load depth matrix\n",
    "        depth_img      = np.load('%s/meta/depth.npy' % (path))\n",
    "        #print('depth_img', depth_img.shape, np.min(depth_img), np.max(depth_img))\n",
    "        depth_img      = depth_img.astype(np.float32).reshape(1, depth_img.shape[1], depth_img.shape[0], 3)\n",
    "        depth_img      = (depth_img - np.min(depth_img)) / (np.max(depth_img) - np.min(depth_img))\n",
    "        data['depth']  = np.append(data['depth'], np.expand_dims(depth_img[:,:,:,0], axis=-1), axis=0)\n",
    "        \n",
    "        # Load normal tensor\n",
    "        normal_img     = np.load('%s/meta/normal.npy' % (path)) \n",
    "        #print('normal_img', normal_img.shape, np.min(normal_img), np.max(normal_img))\n",
    "        normal_img     = normal_img.astype(np.float32).reshape(1, normal_img.shape[1], normal_img.shape[0], 3)\n",
    "        data['normal'] = np.append(data['normal'], normal_img, axis=0)\n",
    "        \n",
    "        # Load position tensor\n",
    "        position_img   = np.load('%s/meta/position.npy' % (path)) \n",
    "        #print('position_img', position_img.shape, np.min(position_img), np.max(position_img))\n",
    "        position_img   = position_img.astype(np.float32).reshape(1, position_img.shape[1], position_img.shape[0], 3)\n",
    "        position_img   = (position_img - np.min(position_img)) / (np.max(position_img) - np.min(position_img))\n",
    "        data['position'] = np.append(data['position'], position_img, axis=0)\n",
    "        \n",
    "        # =============================================================================================\n",
    "        # For each image in the scene folder\n",
    "        \n",
    "        for file in files:\n",
    "            file_path = '%s/%s' % (path, file)\n",
    "            \n",
    "            # Load image\n",
    "            img  = Image.open(file_path) \n",
    "            img  = np.array(img.getdata(), dtype=np.uint8).reshape(1, img.size[1], img.size[0], 3)\n",
    "            \n",
    "            # Extract meta data\n",
    "            p    = re.compile(\"^(.*?) - (\\d*?)\\.png\")\n",
    "            m    = p.search(file) \n",
    "            alg  = m.group(1)\n",
    "            aidx = algs.index(alg)\n",
    "            spp  = np.log2(int(m.group(2)))\n",
    "            \n",
    "            # =========================================================================================\n",
    "            # Add image and meta to data dict \n",
    "            \n",
    "            data['image'] = np.append(data['image'], img, axis=0)\n",
    "            data['scene'] = np.append(data['scene'], np.array([sidx]).astype(np.uint8))\n",
    "            data['alg']   = np.append(data['alg'],   np.array([aidx]).astype(np.uint8))\n",
    "            data['spp']   = np.append(data['spp'],   np.array( [spp]).astype(np.uint8))\n",
    "            \n",
    "            print('Loading: %-120s' % ('%3d %3d %3d %s %s' \n",
    "                  % (sidx, aidx, spp, data['image'].shape, file_path)), end='\\r')\n",
    "            \n",
    "    print()\n",
    "    \n",
    "    # =================================================================================================\n",
    "    # Associate each image with the id of its ground truth image \n",
    "    \n",
    "    for i in range(data['image'].shape[0]):\n",
    "        gt = np.where((       data['scene'][i]  == data['scene']) # GT has the same scene as image[i]\n",
    "                    & (gtalgs[data['scene'][i]] == data['alg'])   # GT uses GT algorithm for image[i]'s scene\n",
    "                    & (gtspps[data['scene'][i]] == data['spp']))  # GT has the GT Sample for image[i]'s scene\n",
    "        \n",
    "        assert (gt[0].shape[0] == 1), 'Assertion that only one GT index should be found each image.'\n",
    "        data['gt'] = np.append(data['gt'], np.array(gt[0]).astype(np.uint16))\n",
    "    \n",
    "    # =================================================================================================\n",
    "    \n",
    "    img_biqi.close()\n",
    "    img_dct.close()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def loadData(data_file, extra_files = []):\n",
    "    data = {}\n",
    "    if (os.path.isfile(data_file + '.npz')):\n",
    "        # =============================================================================================\n",
    "        print('Loading Cached Data')\n",
    "        \n",
    "        raw_data = np.load(data_file + '.npz')\n",
    "        data = {'image':raw_data['image'],\n",
    "                   'depth':raw_data['depth'],\n",
    "                  'normal':raw_data['normal'],\n",
    "                'position':raw_data['position'],\n",
    "                   'scene':raw_data['scene'], \n",
    "                     'alg':raw_data['alg'], \n",
    "                     'spp':raw_data['spp'], \n",
    "                      'gt':raw_data['gt']}\n",
    "    else:\n",
    "        # =============================================================================================\n",
    "        print('Loading Raw Data')\n",
    "        \n",
    "        data = loadRawData()\n",
    "        np.savez(data_file + '.npz', \n",
    "                    image=data['image'], \n",
    "                    depth=data['depth'], \n",
    "                   normal=data['normal'], \n",
    "                 position=data['position'], \n",
    "                    scene=data['scene'], \n",
    "                      alg=data['alg'], \n",
    "                      spp=data['spp'], \n",
    "                       gt=data['gt'])\n",
    "        \n",
    "    # =================================================================================================\n",
    "    \n",
    "    for (data_key, (file_key, file_name)) in extra_files:\n",
    "        print('Loading Extra File: %s[%s] as data[%s]' % (file_name, file_key, data_key))\n",
    "        extra_file = np.load(file_name + '.npz')\n",
    "        data[data_key] = extra_file[file_key]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T15:34:43.094469Z",
     "start_time": "2017-08-21T15:34:43.072399Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def np_mse(img, gtimg):\n",
    "    return np.mean((img - gtimg) ** 2)\n",
    "\n",
    "def np_mae(img, gtimg):\n",
    "    return np.mean(np.abs(img - gtimg))\n",
    "\n",
    "def _np_fspecial_gauss(size, sigma):\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g    = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    g   /= np.sum(g)\n",
    "    return g\n",
    "\n",
    "def np_ssim(img1, img2, size=11, sigma=1.5):\n",
    "    window    = _np_fspecial_gauss(size, sigma) # window shape [size, size]\n",
    "    K1        = 0.01\n",
    "    K2        = 0.03\n",
    "    L         = 1  # depth of image (255 in case the image has a differnt scale)\n",
    "    C1        = (K1*L)**2\n",
    "    C2        = (K2*L)**2\n",
    "    mu1       = convolve2d(img1, window, boundary='symm', mode='same')\n",
    "    mu2       = convolve2d(img2, window, boundary='symm', mode='same')\n",
    "    mu1_sq    = mu1*mu1\n",
    "    mu2_sq    = mu2*mu2\n",
    "    mu1_mu2   = mu1*mu2\n",
    "    sigma1_sq = convolve2d(img1*img1, window, boundary='symm', mode='same') - mu1_sq\n",
    "    sigma2_sq = convolve2d(img2*img2, window, boundary='symm', mode='same') - mu2_sq\n",
    "    sigma12   = convolve2d(img1*img2, window, boundary='symm', mode='same') - mu1_mu2\n",
    "    \n",
    "    value = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Get IQA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T15:34:43.135497Z",
     "start_time": "2017-08-21T15:34:43.096470Z"
    },
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def getOurModel(width, height, optimizer, lossFunc):\n",
    "    print('Constructing IQA Model...')\n",
    "    k             = 3\n",
    "    dropout_rate  = 0.2\n",
    "    leak          = 0.2\n",
    "    fltr_layers   = [256, 256, 256, 256]\n",
    "    full_layers   = [128, 128, 128, 128, 128, 128]\n",
    "    init          = 'he_normal'\n",
    "    \n",
    "    # Input Image\n",
    "    g_rgb  = Input(shape=[height, width, 3], name='in_rgb')\n",
    "    \n",
    "    g = g_rgb\n",
    "    for lvl in range(len(fltr_layers)):\n",
    "        flt = fltr_layers[lvl]\n",
    "        blk = 'conv%02d_' % lvl\n",
    "        \n",
    "        g = Conv2D(flt, k, padding='same', kernel_initializer=init,  name=blk+'c'  )(g)\n",
    "        g = BatchNormalization(                                      name=blk+'b'  )(g)\n",
    "        g = Activation('relu',                                       name=blk+'a'  )(g)        \n",
    "        #g = PReLU(                                                   name=blk+'a'  )(g)\n",
    "        #g = LeakyReLU(alpha=leak,                                    name=blk+'a'  )(g)\n",
    "        #g = Dropout(dropout_rate,                                    name=blk+'d'  )(g)\n",
    "    \n",
    "        \n",
    "    for lvl in range(len(full_layers)):\n",
    "        flt = full_layers[lvl]\n",
    "        blk = 'full%02d_' % lvl\n",
    "        \n",
    "        g = Conv2D(flt, 1, padding='same', kernel_initializer=init,  name=blk+'c'  )(g)\n",
    "        g = BatchNormalization(                                      name=blk+'b'  )(g)\n",
    "        g = Activation('relu',                                       name=blk+'a'  )(g)\n",
    "        #g = PReLU(                                                   name=blk+'a'  )(g)\n",
    "        #g = LeakyReLU(alpha=leak,                                    name=blk+'a'  )(g)\n",
    "        #g = Dropout(dropout_rate,                                    name=blk+'d'  )(g)\n",
    "        \n",
    "    #g = Dropout(dropout_rate,                                        name='out_d'  )(g)\n",
    "    g = Conv2D(1, 1,       padding='same', kernel_initializer=init,  name='out_c'  )(g)\n",
    "    g_iqa = Activation('relu',                                       name='out_iqa')(g)  \n",
    "    \n",
    "    #g_iqa = Conv2D(1, 1,   padding='same', kernel_initializer=init,  name='out_iqa')(g)\n",
    "    \n",
    "    # =========================================================================================\n",
    "    \n",
    "    iqa = Model(g_rgb, g_iqa, name='iqa-fcnn')\n",
    "    iqa.compile(loss=lossFunc, optimizer=optimizer())\n",
    "    \n",
    "    #iqa.summary()\n",
    "    #plot_model(iqa, to_file='fcnn-iqa-model.png')\n",
    "    \n",
    "    return iqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T15:34:43.717062Z",
     "start_time": "2017-08-21T15:34:43.137500Z"
    },
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_config(root_path, resume, getModel, optimizer, lossFunc, scale, data, scene_name, model_name, config_name, gen, genVal, \n",
    "                     num_epochs, batches_per_epoch, val_per_epoch, plot_per_epoch, batch_size, patch_size):    \n",
    "    weights_dir     = '%s/%s/%s'    % (root_path, scene_name, model_name)\n",
    "    weights_file    = '%s/%s - %s'  % (weights_dir, model_name, config_name)\n",
    "    \n",
    "    common_dir      = '%s/%s'       % (root_path, scene_name)\n",
    "    common_file     = '%s/%s - %s'  % (common_dir, model_name, config_name)\n",
    "    \n",
    "    print('Validation Scene: [ %s ] Model: [ %s ] Config: [ %s ]' % (scene_name, model_name, config_name))\n",
    "    \n",
    "    if (not os.path.exists(weights_dir)): os.makedirs(weights_dir)\n",
    "\n",
    "    # Load Model\n",
    "    iqa = getModel(patch_size, patch_size, optimizer, lossFunc)\n",
    "    #learning_rate_scheduler = LearningRateScheduler(step_decay)\n",
    "    \n",
    "    train_colour = '#0084B2' #'#2222aa'\n",
    "    val_colour   = '#FFA649' #'#aa2222'\n",
    "    exm_colour   = '#FF4B49'\n",
    "    \n",
    "    # Resume\n",
    "    epoch     = 0\n",
    "    epochs    = []\n",
    "    g_losses  = []\n",
    "    gv_losses = []\n",
    "    g_pccs    = []\n",
    "    gv_pccs   = []\n",
    "    g_sroccs  = []\n",
    "    gv_sroccs = []\n",
    "    g_ktccs   = []\n",
    "    gv_ktccs  = []\n",
    "    if (resume and os.path.isfile(weights_file + ' - weights.h5')):\n",
    "        iqa.load_weights(         weights_file + ' - weights.h5')\n",
    "        raw_data  = np.load(      weights_file + ' - stats.npz')\n",
    "        epoch     = raw_data['epoch'    ][0] + 1\n",
    "        epochs    = raw_data['epochs'   ].tolist()\n",
    "        g_losses  = raw_data['g_losses' ].tolist()\n",
    "        gv_losses = raw_data['gv_losses'].tolist()\n",
    "        g_pccs    = raw_data['g_pccs'   ].tolist()\n",
    "        gv_pccs   = raw_data['gv_pccs'  ].tolist()\n",
    "        g_sroccs  = raw_data['g_sroccs' ].tolist()\n",
    "        gv_sroccs = raw_data['gv_sroccs'].tolist()\n",
    "        g_ktccs   = raw_data['g_ktccs'  ].tolist()\n",
    "        gv_ktccs  = raw_data['gv_ktccs' ].tolist()\n",
    "        print('Resuming from epoch:', epoch)        \n",
    "    else:\n",
    "        print('Starting from epoch: 0')\n",
    "\n",
    "    # Train generator models \n",
    "    for epoch in range(epoch, num_epochs+1):\n",
    "        epochs.append(epoch)\n",
    "        \n",
    "        # Train generator\n",
    "        h = iqa.fit_generator(gen, steps_per_epoch=batches_per_epoch, \n",
    "                              validation_data=genVal, validation_steps=val_per_epoch,\n",
    "                              initial_epoch=epoch, epochs=epoch+1, verbose=0) # callbacks=[learning_rate_scheduler]\n",
    "        \n",
    "        # Update plots\n",
    "        g_losses.append( h.history[    'loss'][-1])\n",
    "        gv_losses.append(h.history['val_loss'][-1])\n",
    "\n",
    "        plot_size = (plot_per_epoch * batch_size)\n",
    "        g_input   = np.zeros((plot_size, patch_size, patch_size, 3), dtype=np.float32)\n",
    "        g_true    = np.zeros((plot_size, patch_size, patch_size, 1), dtype=np.float32)\n",
    "        g_pred    = np.zeros((plot_size, patch_size, patch_size, 1), dtype=np.float32)\n",
    "        gv_input  = np.zeros((plot_size, patch_size, patch_size, 3), dtype=np.float32)\n",
    "        gv_true   = np.zeros((plot_size, patch_size, patch_size, 1), dtype=np.float32)\n",
    "        gv_pred   = np.zeros((plot_size, patch_size, patch_size, 1), dtype=np.float32)\n",
    "        \n",
    "        for plot_batch in range(plot_per_epoch):\n",
    "            ( gg_input,  gg_true) = next(gen)\n",
    "            (ggv_input, ggv_true) = next(genVal)\n",
    "            gg_pred  = iqa.predict( gg_input)\n",
    "            ggv_pred = iqa.predict(ggv_input)\n",
    "            \n",
    "            plot_idx = np.arange(batch_size) + (plot_batch * batch_size)\n",
    "            \n",
    "            g_input[plot_idx,:,:,:]  = gg_input[:,:,:,:]\n",
    "            g_true[plot_idx,:,:,:]   = gg_true[:,:,:,:]\n",
    "            g_pred[plot_idx,:,:,:]   = gg_pred[:,:,:,:]\n",
    "            \n",
    "            gv_input[plot_idx,:,:,:] = ggv_input[:,:,:,:]\n",
    "            gv_true[plot_idx,:,:,:]  = ggv_true[:,:,:,:]\n",
    "            gv_pred[plot_idx,:,:,:]  = ggv_pred[:,:,:,:]\n",
    "\n",
    "        g_pccs.append(   pearsonr(   g_true.flatten(),  g_pred.flatten())[0])\n",
    "        gv_pccs.append(  pearsonr(  gv_true.flatten(), gv_pred.flatten())[0])\n",
    "        g_sroccs.append( spearmanr(  g_true.flatten(),  g_pred.flatten())[0])\n",
    "        gv_sroccs.append(spearmanr( gv_true.flatten(), gv_pred.flatten())[0])\n",
    "        g_ktccs.append(  kendalltau( g_true.flatten(),  g_pred.flatten())[0])\n",
    "        gv_ktccs.append( kendalltau(gv_true.flatten(), gv_pred.flatten())[0])\n",
    "\n",
    "        figw   = 1500\n",
    "        figh   = 1400\n",
    "        figdpi = 80\n",
    "        fig = plt.figure(facecolor='white', figsize=(figw/figdpi, figh/figdpi), dpi=figdpi)\n",
    "        fig.subplots_adjust(hspace=.3, wspace=.3)\n",
    "        plt.suptitle(('Scene: [ %s ] Model: [ %s ] Config: [ %s ] \\n' +\n",
    "                      ' Batch Size: [ %d ] Batches Per Epoch: [ %d ] Validation Batches Per Epoch: [ %d ] \\n' +\n",
    "                      ' Epoch: [ %d ] Batches: [ %d ] Patches: [ %d ] Pixels: [ %d ]') % \n",
    "                     (scene_name, model_name,config_name, \n",
    "                      batch_size, batches_per_epoch, val_per_epoch, \n",
    "                      epoch, ((epoch+1) * batches_per_epoch), ((epoch+1) * batches_per_epoch * batch_size), \n",
    "                      ((epoch+1) * batches_per_epoch * batch_size * patch_size * patch_size)))\n",
    "        \n",
    "        plt.subplot(3,3,1)\n",
    "        plt.title('Loss - Batches: %d Patches: %d \\n Train: %f Val: %f' % \n",
    "                  (((epoch+1) * batches_per_epoch), ((epoch+1) * batches_per_epoch * batch_size), g_losses[-1], gv_losses[-1]))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.yscale('log')\n",
    "        plt.grid(which='major', linestyle='-')\n",
    "        plt.grid(which='minor', linestyle=':')\n",
    "\n",
    "        plt.plot(epochs, g_losses,  color=train_colour, label='Train')\n",
    "        plt.plot(epochs, gv_losses, color=val_colour, label='Val')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(3,3,2)\n",
    "        plt.title('%d Patch - Pixel Correlation' % (plot_size))\n",
    "        plt.xlabel('True Quality')\n",
    "        plt.ylabel('Predicted Quality')\n",
    "        plt.grid(which='major', linestyle='-')\n",
    "        plt.grid(which='minor', linestyle=':')\n",
    "\n",
    "        plt.plot(g_true.flatten(),  g_pred.flatten(),  color=train_colour, linestyle=' ', marker='^', markersize=0.5, alpha=0.1, label='Train')\n",
    "        plt.plot(gv_true.flatten(), gv_pred.flatten(),   color=val_colour, linestyle=' ', marker='v', markersize=0.5, alpha=0.1, label='Val')\n",
    "        plt.plot([0, 1], [0, 1], color='black')\n",
    "        \n",
    "        plt.plot(gv_true[0,:,:,:].flatten(), gv_pred[0,:,:,:].flatten(), color=exm_colour, \n",
    "                 linestyle=' ', marker='v', markersize=0.5, alpha=0.2, label='Example Val')\n",
    "        \n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(3,3,3)\n",
    "        plt.title('%d Patch - Pixel Distribution' % (plot_size))\n",
    "        plt.xlabel('Quality')\n",
    "        plt.ylabel('Frequency')\n",
    "\n",
    "        m0 = np.minimum(np.minimum(np.min(g_true), np.min(gv_true)), \n",
    "                        np.minimum(np.min(g_pred), np.min(gv_pred)))\n",
    "        \n",
    "        m1 = np.maximum(np.maximum(np.max(g_true), np.max(gv_true)), \n",
    "                        np.maximum(np.max(g_pred), np.max(gv_pred)))\n",
    "        \n",
    "        num_bins  = np.floor(np.sqrt(plot_size - 1)).astype(np.int32)\n",
    "        bins = np.linspace(m0, m1, num_bins)\n",
    "        \n",
    "        plt.hist(g_true.flatten(),  bins, histtype='step', color=train_colour, label='Train Truth')\n",
    "        plt.hist(g_pred.flatten(),  bins, histtype='step', linestyle=':', color=train_colour, label='Train Prediction')\n",
    "        plt.hist(gv_true.flatten(), bins, histtype='step', color=val_colour, label='Val Truth')\n",
    "        plt.hist(gv_pred.flatten(), bins, histtype='step', linestyle=':', color=val_colour, label='Val Prediction')\n",
    "        \n",
    "        plt.legend()\n",
    "        \n",
    "        #\n",
    "        \n",
    "        plt.subplot(3,3,4)\n",
    "        plt.title('%d Patch - Per Pixel Pearsons \\n Train: %f Val: %f' % (plot_size, g_pccs[-1], gv_pccs[-1]))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('1 - PCC')\n",
    "        plt.yscale('log')\n",
    "        plt.grid(which='major', linestyle='-')\n",
    "        plt.grid(which='minor', linestyle=':')\n",
    "\n",
    "        plt.plot(epochs, 1-np.abs(g_pccs),  color=train_colour, label='Train')\n",
    "        plt.plot(epochs, 1-np.abs(gv_pccs), color=val_colour, label='Val')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(3,3,5)\n",
    "        plt.title('%d Patch - Per Pixel Spearmans \\n Train: %f Val: %f' % (plot_size, g_sroccs[-1], gv_sroccs[-1]))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('1 - SROCC')\n",
    "        plt.yscale('log')\n",
    "        plt.grid(which='major', linestyle='-')\n",
    "        plt.grid(which='minor', linestyle=':')\n",
    "\n",
    "        plt.plot(epochs, 1-np.abs(g_sroccs),  color=train_colour, label='Train')\n",
    "        plt.plot(epochs, 1-np.abs(gv_sroccs), color=val_colour, label='Val')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(3,3,6)\n",
    "        plt.title('%d Patch - Per Pixel Kendalls Tau \\n Train: %f Val: %f' % (plot_size, g_ktccs[-1], gv_ktccs[-1]))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('1 - TAU')\n",
    "        plt.yscale('log')\n",
    "        plt.grid(which='major', linestyle='-')\n",
    "        plt.grid(which='minor', linestyle=':')\n",
    "\n",
    "        plt.plot(epochs, 1-np.abs(g_ktccs),  color=train_colour, label='Train')\n",
    "        plt.plot(epochs, 1-np.abs(gv_ktccs), color=val_colour, label='Val')\n",
    "        plt.legend()\n",
    "        \n",
    "        #\n",
    "        pad = 6\n",
    "        \n",
    "        plt.subplot(3,3,7)\n",
    "        plt.title('Example Image')\n",
    "        plt.imshow(gv_input[0,:,:,:] / scale)\n",
    "        \n",
    "        plt.subplot(3,3,8)\n",
    "        plt.title('Example Image - Prediction')\n",
    "        plt.imshow(gv_pred[0,pad:-pad,pad:-pad,0])\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3,3,9)\n",
    "        plt.title('Example Image - Truth')\n",
    "        plt.imshow(gv_true[0,pad:-pad,pad:-pad,0])\n",
    "        plt.colorbar()\n",
    "        \n",
    "        clear_output()\n",
    "        plt.show()\n",
    "        #fig.savefig(weights_file + '.png', format='png', dpi=80)\n",
    "        fig.savefig(weights_file + '.png', format='png', dpi=80)\n",
    "        fig.savefig(common_file  + '.png', format='png', dpi=80)\n",
    "\n",
    "        print(' '*120, end='\\r')\n",
    "        print('Validation Scene %s | Epoch %d | Loss (%f, %f) PCC (%f, %f) SROCC (%f, %f) TAU (%f, %f)' \n",
    "              % (scene_name, epoch, g_losses[-1], gv_losses[-1], g_pccs[-1], gv_pccs[-1], \n",
    "                 g_sroccs[-1], gv_sroccs[-1], g_ktccs[-1], gv_ktccs[-1]), end='\\r')\n",
    "\n",
    "        # Save\n",
    "        iqa.save_weights(weights_file + ' - weights.h5')\n",
    "        np.savez(weights_file + ' - stats.npz', \n",
    "                 epoch     = np.array([epoch],   dtype=np.uint32 ), epochs    = np.array(epochs,    dtype=np.float32),\n",
    "                 g_losses  = np.array(g_losses,  dtype=np.float32), gv_losses = np.array(gv_losses, dtype=np.float32),\n",
    "                 g_pccs    = np.array(g_pccs,    dtype=np.float32), gv_pccs   = np.array(gv_pccs,   dtype=np.float32),\n",
    "                 g_sroccs  = np.array(g_sroccs,  dtype=np.float32), gv_sroccs = np.array(gv_sroccs, dtype=np.float32),\n",
    "                 g_ktccs   = np.array(g_ktccs,   dtype=np.float32), gv_ktccs  = np.array(gv_ktccs,  dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-21T15:34:40.447Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_config(root_path, getModel, optimizer, lossFunc, minimizeFunc, scale, data, scene, scene_name, model_name, config_name):    \n",
    "    weights_dir     = '%s/%s/%s'    % (root_path, scene_name, model_name)\n",
    "    weights_file    = '%s/%s - %s'  % (weights_dir, model_name, config_name)\n",
    "    \n",
    "    common_dir      = '%s/%s'       % (root_path, scene_name)\n",
    "    common_file     = '%s/%s - %s'  % (common_dir, model_name, config_name)\n",
    "    \n",
    "    print('Validation Scene: [ %s ] Model: [ %s ] Config: [ %s ]' % (scene_name, model_name, config_name))\n",
    "    \n",
    "    if (not os.path.exists(weights_dir)): os.makedirs(weights_dir)\n",
    "        \n",
    "    test_path = weights_dir + 'test/'\n",
    "    \n",
    "    if (not os.path.exists(test_path)): os.makedirs(test_path)\n",
    "\n",
    "    # Load Model\n",
    "    iqa = getModel(512, 512, optimizer, lossFunc)\n",
    "    \n",
    "    train_colour = '#0084B2' #'#2222aa'\n",
    "    val_colour   = '#FFA649' #'#aa2222'\n",
    "    exm_colour   = '#FF4B49'\n",
    "    \n",
    "    if (os.path.isfile(     weights_file + ' - weights.h5')):\n",
    "        iqa.load_weights(   weights_file + ' - weights.h5')\n",
    "        raw_data  = np.load(weights_file + ' - stats.npz')\n",
    "        epoch     = raw_data['epoch'][0]\n",
    "        print('Testing at epoch:', epoch)\n",
    "    else:\n",
    "        print('Could not load model')      \n",
    "        return\n",
    "    \n",
    "    def genImagePair(data, scene, alg):\n",
    "        idxs     = np.array(np.where((np.arange(data['gt'].shape[0]) != data['gt'])\n",
    "                                                & (data['scene'] == scene)\n",
    "                                                  & (data['alg'] == alg))) \n",
    "        gtidxs   = data['gt'][idxs]\n",
    "        for j in range(idxs.shape[1]):\n",
    "            bimg        = data['image'          ][  idxs[0,j],:,:,:].astype(np.float32) / 255.\n",
    "            bgts        = data['image'          ][gtidxs[0,j],:,:,:].astype(np.float32) / 255.\n",
    "            bspp        = data['spp'            ][  idxs[0,j]]\n",
    "            yield (bspp, bimg, bgts)\n",
    "    \n",
    "    def evaluate_image(iqa, img, gtimg, scale):\n",
    "        \n",
    "        m_pred = iqa.predict(np.expand_dims(img, axis=0))[0,:,:,0]\n",
    "        #print(m_pred.shape)\n",
    "        \n",
    "        m_true = minimizeFunc(img * scale, gtimg * scale)[:,:,0]\n",
    "        #print(m_true.shape)\n",
    "        \n",
    "        return (m_pred, m_true)\n",
    "    \n",
    "    cnt = 0\n",
    "    for (alg, alg_name) in enumerate(['path', 'bdpt', 'pssmlt', 'mlt', 'manifold-mlt', 'erpt', 'manifold-erpt']):\n",
    "        for (spp, img, gtimg) in genImagePair(data, scene, alg):\n",
    "            cnt += 1\n",
    "            \n",
    "            (m_pred, m_true) = evaluate_image(iqa, img, gtimg, scale)   \n",
    "            mu_pred = np.mean(m_pred)\n",
    "            mu_true = np.mean(m_true)\n",
    "            \n",
    "            m0 = np.minimum(np.min(m_pred), np.min(m_true))\n",
    "            m1 = np.maximum(np.max(m_pred), np.max(m_true))\n",
    "            \n",
    "            cc = plt.get_cmap('viridis') \n",
    "            plt.imsave('%sscene-%d-alg-%s-spp-%d-pred-ssim.png' % (test_path, val_scene, alg_name, spp), m_pred, cmap=cc, vmin=m0, vmax=m1) #\n",
    "            plt.imsave('%sscene-%d-alg-%s-spp-%d-true-ssim.png' % (test_path, val_scene, alg_name, spp), m_true, cmap=cc, vmin=m0, vmax=m1) #\n",
    "            \n",
    "            figw   = 2500\n",
    "            figh   = 800\n",
    "            figdpi = 80\n",
    "            fig = plt.figure(facecolor='white', figsize=(figw/figdpi, figh/figdpi), dpi=figdpi)\n",
    "            fig.subplots_adjust(hspace=.3, wspace=.3)\n",
    "            \n",
    "            plt.subplot(1,4,1)\n",
    "            plt.title('Noisy Image')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img)\n",
    "            \n",
    "            plt.subplot(1,4,2)\n",
    "            plt.title('Predicted MAE Map')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(m_pred, cmap=cc, vmin=m0, vmax=m1)\n",
    "            #plt.colorbar()\n",
    "            \n",
    "            plt.subplot(1,4,3)\n",
    "            plt.title('True MAE Map')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(m_true, cmap=cc, vmin=m0, vmax=m1)\n",
    "            #plt.colorbar()\n",
    "            \n",
    "            plt.subplot(1,4,4)\n",
    "            plt.title('Ground Truth Image')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(gtimg)\n",
    "            \n",
    "            clear_output()\n",
    "            plt.show()\n",
    "            fig.savefig('%sscene-%d-alg-%s-spp-%d.eps' % (test_path, val_scene, alg_name, spp), format='eps', dpi=80, bbox_inches='tight')\n",
    "            \n",
    "            print('Validation Scene: [ %s ] Model: [ %s ] Config: [ %s ] Alg: [ %s ] Count: [ %d ]' % (scene_name, model_name, config_name, alg_name, cnt))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-21T15:34:40.449Z"
    },
    "code_folding": [
     23,
     37
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load Dataset\n",
    "    data                = loadData('MonteCarlo-IMDB') # , [('ps 32 - bin', ('bins_idxs', 'bins'))]\n",
    "    scene_names         = ['cbox', 'torus', 'veach_bidir', 'veach_door', 'sponza']\n",
    "    \n",
    "    resume              = True\n",
    "    \n",
    "    # How long to train for\n",
    "    num_epochs          = 2 ** 7\n",
    "    \n",
    "    # How many examples to train with each epoch\n",
    "    batches_per_epoch   = 2 ** 8\n",
    "    val_per_epoch       = 2 ** 8\n",
    "    plot_per_epoch      = 2 ** 4\n",
    "    batch_size          = 2 ** 4\n",
    "    \n",
    "    # Patch size for network training\n",
    "    patch_size          = 2 ** 6\n",
    "    \n",
    "    # Stability term\n",
    "    scale               = 1\n",
    "    \n",
    "    root_path           = 'output/fcnn - run 14'\n",
    "    \n",
    "    def dataExtractor(data, patch_size, val, val_scene):\n",
    "        idxs       = np.array(np.where((np.arange(data['gt'].shape[0]) != data['gt'])\n",
    "                                     & (data['scene'] != 1) # Exclude torus scene completely\n",
    "                                     #& (data['alg'] == 0)\n",
    "                                     & (((    val) & (data['scene'] == val_scene)) \n",
    "                                      | ((not val) & (data['scene'] != val_scene))))) \n",
    "        gtidxs     = data['gt'][idxs]\n",
    "        w, h       = data['image'].shape[2], data['image'].shape[1]\n",
    "        \n",
    "        num_images = idxs.shape[1]\n",
    "        num_data   = num_images * (w-patch_size-1) * (h-patch_size-1)\n",
    "        \n",
    "        return (idxs, gtidxs, w, h, num_images, num_data)\n",
    "    \n",
    "    def genRandomMinibatch(minimizeFunc, jitterFunc, scale, data, patch_size, batch_size, val, val_scene):\n",
    "        (idxs, gtidxs, w, h, num_images, num_data) = dataExtractor(data, patch_size, val, val_scene)\n",
    "\n",
    "        bimgs     = np.zeros((batch_size, patch_size, patch_size, 3), dtype=np.float32)\n",
    "        bssim     = np.zeros((batch_size, patch_size, patch_size, 1), dtype=np.float32)\n",
    "\n",
    "        while (True):\n",
    "            ids,y,x = np.unravel_index(np.random.randint(num_data, size=batch_size), (idxs.shape[1], (h-patch_size-1), (w-patch_size-1)))\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                bimg = data['image'][  idxs[0,ids[j]],y[j]:(y[j]+patch_size),x[j]:(x[j]+patch_size),:].astype(np.float32) / 255.\n",
    "                bgts = data['image'][gtidxs[0,ids[j]],y[j]:(y[j]+patch_size),x[j]:(x[j]+patch_size),:].astype(np.float32) / 255.\n",
    "\n",
    "                if (jitterFunc != None):\n",
    "                    (bimg, bgts) = jitterFunc(bimg, bgts)\n",
    "\n",
    "                bimg = bimg * scale\n",
    "                bgts = bgts * scale\n",
    "\n",
    "                bimgs[j,:,:,:] = bimg\n",
    "                bssim[j,:,:,:] = minimizeFunc(bimgs[j,:,:,:], bgts)\n",
    "            yield (bimgs, bssim)\n",
    "            \n",
    "    def genPermutedMinibatch(minimizeFunc, jitterFunc, scale, data, patch_size, batch_size, val, val_scene):\n",
    "        (idxs, gtidxs, w, h, num_images, num_data) = dataExtractor(data, patch_size, val, val_scene)\n",
    "\n",
    "        bimgs     = np.zeros((batch_size, patch_size, patch_size, 3), dtype=np.float32)\n",
    "        bssim     = np.zeros((batch_size, patch_size, patch_size, 1), dtype=np.float32)\n",
    "\n",
    "        while (True):\n",
    "            ids = np.random.permutation(idxs.shape[1])\n",
    "            y   = np.random.randint((h-patch_size-1), size=idxs.shape[1])\n",
    "            x   = np.random.randint((w-patch_size-1), size=idxs.shape[1])\n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                bimg = data['image'][  idxs[0,ids[j]],y[j]:(y[j]+patch_size),x[j]:(x[j]+patch_size),:].astype(np.float32) / 255.\n",
    "                bgts = data['image'][gtidxs[0,ids[j]],y[j]:(y[j]+patch_size),x[j]:(x[j]+patch_size),:].astype(np.float32) / 255.\n",
    "\n",
    "                if (jitterFunc != None):\n",
    "                    (bimg, bgts) = jitterFunc(bimg, bgts)\n",
    "\n",
    "                bimg = bimg * scale\n",
    "                bgts = bgts * scale\n",
    "\n",
    "                bimgs[j,:,:,:] = bimg\n",
    "                bssim[j,:,:,:] = minimizeFunc(bimgs[j,:,:,:], bgts)\n",
    "            yield (bimgs, bssim)\n",
    "    \n",
    "    def jitterRotFlip(img, gtimg):\n",
    "        # Flip Image Left to Right\n",
    "        flip = np.random.rand()\n",
    "        if (flip > 0.5):\n",
    "            img   = img[:,::-1,:]\n",
    "            gtimg = gtimg[:,::-1,:]\n",
    "\n",
    "        # Rotate Image in intervals of 90 degrees\n",
    "        rot = np.random.randint(4)\n",
    "        if (rot > 0):\n",
    "            img   = np.rot90(img,   rot, axes=(0,1))\n",
    "            gtimg = np.rot90(gtimg, rot, axes=(0,1))\n",
    "        return (img, gtimg)\n",
    "        \n",
    "    def jitterRotFlipHSV(img, gtimg):\n",
    "        (img, gtimg) = jitterRotFlip(img, gtimg)\n",
    "        \n",
    "        # Convert to HSV\n",
    "        img   = matplotlib.colors.rgb_to_hsv(img)\n",
    "        gtimg = matplotlib.colors.rgb_to_hsv(gtimg)\n",
    "\n",
    "        # Additive Shift Hue mod 1\n",
    "        hue_f = np.random.uniform(0., 1.)\n",
    "        img[:,:,0]   = np.mod(img[:,:,0]   + (hue_f), 1.)\n",
    "        gtimg[:,:,0] = np.mod(gtimg[:,:,0] + (hue_f), 1.)\n",
    "\n",
    "        # Additive Gain on Saturation\n",
    "        sat_p = 0.3\n",
    "        sat_f = np.random.uniform(-sat_p, sat_p)\n",
    "        img[:,:,1]   = np.clip(img[:,:,1]   + (sat_f), 0., 1.)\n",
    "        gtimg[:,:,1] = np.clip(gtimg[:,:,1] + (sat_f), 0., 1.)\n",
    "\n",
    "        # Additive Gain on Brightness\n",
    "        brt_p = 0.3\n",
    "        brt_f = np.random.uniform(-brt_p, brt_p)\n",
    "        img[:,:,2]   = np.clip(img[:,:,2]   + (brt_f), 0., 1.)\n",
    "        gtimg[:,:,2] = np.clip(gtimg[:,:,2] + (brt_f), 0., 1.)\n",
    "\n",
    "        # Convert to RGB\n",
    "        img   = matplotlib.colors.hsv_to_rgb(img)\n",
    "        gtimg = matplotlib.colors.hsv_to_rgb(gtimg)\n",
    "        return (img, gtimg)\n",
    "        \n",
    "    \n",
    "    def ssim_map(img, gtimg):\n",
    "        return np.clip(np.expand_dims(np_ssim(np.mean(img, axis=-1), np.mean(gtimg, axis=-1)), axis=-1), 0., 1.)\n",
    "    \n",
    "    def charbonnier_loss(y_true, y_pred, eps=1e-3):\n",
    "        return K.mean(K.batch_flatten(K.sqrt(K.square(y_true - y_pred) + (eps ** 2))))\n",
    "    \n",
    "    def K_cov(y_true, y_pred):\n",
    "        return K.mean( (y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred)) )\n",
    "    \n",
    "    def K_pcc(y_true, y_pred):\n",
    "        return K_cov(y_true, y_pred) / K.sqrt(K.var(y_true) * K.var(y_pred))\n",
    "    \n",
    "    def charbonnier_pcc_loss(y_true, y_pred):\n",
    "        return charbonnier_loss(y_true, y_pred) + (1. - K_pcc(y_true, y_pred))\n",
    "    \n",
    "    # Experiment Configurations\n",
    "    test_scenes         = [0, 2, 3, 4]\n",
    "    \n",
    "    test_funcs          = [('ssim', ssim_map)] \n",
    "    \n",
    "    test_generators     = [('perm-mb', genPermutedMinibatch)] # ('rnd-mb', genRandomMinibatch)\n",
    "    \n",
    "    test_optimizers     = [('adam', Adam)]\n",
    "    \n",
    "    test_models         = [('ours', getOurModel)]\n",
    "    \n",
    "    test_jitter         = [('rot+flip+hsv', jitterRotFlipHSV), ('rot+flip', jitterRotFlip), ('none', None)] \n",
    "    # \n",
    "    \n",
    "    test_loss           = [('charbonnier+pcc', charbonnier_pcc_loss), , ('charbonnier', charbonnier_loss), \n",
    "                           ('mse', mean_squared_error), ('mae', mean_absolute_error)] \n",
    "    \n",
    "    for val_scene                                     in test_scenes:\n",
    "        for (model_name, getModel)                    in test_models:\n",
    "            for (minimize_name, minimizeFunc)         in test_funcs:\n",
    "                for (optimize_name, optimizer)        in test_optimizers:\n",
    "                    for (generator_name, generator)   in test_generators:\n",
    "                        for (jitter_name, jitterFunc) in test_jitter:\n",
    "                            for (loss_name, lossFunc) in test_loss:\n",
    "                                val_scene_name = scene_names[val_scene]\n",
    "                                config_name    = ('g (%s) - o (%s) - j (%s) - l (%s) - m (%s) - p (%d)' \n",
    "                                                  % (generator_name, optimize_name, jitter_name, loss_name, minimize_name, patch_size))\n",
    "\n",
    "                                gen    = generator(minimizeFunc, jitterFunc, scale, data, patch_size, batch_size, val=False, val_scene=val_scene)\n",
    "                                genVal = generator(minimizeFunc,       None, scale, data, patch_size, batch_size, val= True, val_scene=val_scene)\n",
    "\n",
    "                                train_config(root_path, resume, getModel, optimizer, lossFunc, scale, data, val_scene_name, model_name, config_name, \n",
    "                                             gen, genVal, num_epochs, batches_per_epoch, val_per_epoch, plot_per_epoch, batch_size, patch_size)\n",
    "                                \n",
    "                                test_config(root_path, getModel, optimizer, lossFunc, minimizeFunc, \n",
    "                                            scale, data, val_scene, val_scene_name, model_name, config_name)\n",
    "                        \n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    print()\n",
    "print('\\nHalting...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "notify_time": "10"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
